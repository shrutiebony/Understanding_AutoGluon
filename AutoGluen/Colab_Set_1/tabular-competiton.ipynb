{"cells":[{"cell_type":"markdown","id":"0fa7eb3d","metadata":{"id":"0fa7eb3d"},"source":["# How to use AutoGluon for Kaggle competitions\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb)\n","[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb)\n","\n","\n","\n","This tutorial will teach you how to use AutoGluon to become a serious Kaggle competitor without writing lots of code.\n","We first outline the general steps to use AutoGluon in Kaggle contests. Here, we assume the competition involves tabular data which are stored in one (or more) CSV files.\n","\n","1) Run Bash command: pip install kaggle\n","\n","2) Navigate to: https://www.kaggle.com/account and create an account (if necessary).\n","Then , click on \"Create New API Token\" and move downloaded file to this location on your machine: `~/.kaggle/kaggle.json`. For troubleshooting, see [Kaggle API instructions](https://www.kaggle.com/docs/api).\n","\n","3) To download data programmatically: Execute this Bash command in your terminal:\n","\n","`kaggle competitions download -c [COMPETITION]`\n","\n","Here, [COMPETITION] should be replaced by the name of the competition you wish to enter.\n","Alternatively, you can download data manually: Just navigate to website of the Kaggle competition you wish to enter, click \"Download All\", and accept the competition's terms.\n","\n","4) If the competition's training data is comprised of multiple CSV files, use [pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html) to properly merge/join them into a single data table where rows = training examples, columns = features.\n","\n","5) Run autogluon `fit()` on the resulting data table.\n","\n","6) Load the test dataset from competition (again making the necessary merges/joins to ensure it is in the exact same format as the training data table), and then call autogluon `predict()`.  Subsequently use [pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) to load the competition's `sample_submission.csv` file into a DataFrame, put the AutoGluon predictions in the right column of this DataFrame, and finally save it as a CSV file via [pandas.to_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html). If the competition does not offer a sample submission file, you will need to create the submission file yourself by appropriately reformatting AutoGluon's test predictions.\n","\n","7) Submit your predictions via Bash command:\n","\n","`kaggle competitions submit -c [COMPETITION] -f [FILE] -m [\"MESSAGE\"]`\n","\n","Here, [COMPETITION] again is the competition's name, [FILE] is the name of the CSV file you created with your predictions, and [\"MESSAGE\"] is a string message you want to record with this submitted entry. Alternatively, you can  manually upload your file of predictions on the competition website.\n","\n","8) Finally, navigate to competition leaderboard website to see how well your submission performed!\n","It may take time for your submission to appear.\n","\n","\n","\n","Below, we demonstrate how to do steps (4)-(6) in Python for a specific Kaggle competition: [ieee-fraud-detection](https://www.kaggle.com/c/ieee-fraud-detection/).\n","This means you'll need to run the above steps with `[COMPETITION]` replaced by `ieee-fraud-detection` in each command.  Here, we assume you've already completed steps (1)-(3) and the data CSV files are available on your computer. To begin step (4), we first load the competition's training data into Python:"]},{"cell_type":"code","source":["!pip install kaggle"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gI2PnPCSIA4D","executionInfo":{"status":"ok","timestamp":1726178935348,"user_tz":420,"elapsed":11222,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"f9abcf5e-f085-4c4e-a6e8-62a074032915"},"id":"gI2PnPCSIA4D","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.8)\n"]}]},{"cell_type":"markdown","source":["helps you to upload a file from your local machine"],"metadata":{"id":"q7svqgSCTSJB"},"id":"q7svqgSCTSJB"},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":90},"id":"H4cXdFtWTINu","executionInfo":{"status":"ok","timestamp":1726179224046,"user_tz":420,"elapsed":7046,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"cf573b35-f42c-4145-ee5a-098e918ad3ff"},"id":"H4cXdFtWTINu","execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-40fff41b-186f-4406-81da-ab9054466884\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-40fff41b-186f-4406-81da-ab9054466884\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"prafuljohn\",\"key\":\"a7fe4b89451161b04c1617a7bb820f07\"}'}"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"pfkqEm8nHNud"},"id":"pfkqEm8nHNud","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls /root/\n"],"metadata":{"id":"bTRJjrP_R3Hk"},"id":"bTRJjrP_R3Hk","execution_count":null,"outputs":[]},{"cell_type":"code","source":["!kaggle competitions download -c ieee-fraud-detection"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UZ2pDKVaIzk2","executionInfo":{"status":"ok","timestamp":1726179247485,"user_tz":420,"elapsed":7802,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"e8697b89-6a98-402d-e8e1-03c79506f3e2"},"id":"UZ2pDKVaIzk2","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading ieee-fraud-detection.zip to /content\n"," 98% 116M/118M [00:05<00:00, 23.3MB/s]\n","100% 118M/118M [00:05<00:00, 20.7MB/s]\n"]}]},{"cell_type":"code","source":["!unzip ieee-fraud-detection.zip"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"26r1m023JNmE","executionInfo":{"status":"ok","timestamp":1726179320193,"user_tz":420,"elapsed":14094,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"29dbf1f2-1ea2-48b3-ac83-d9b2e8e8532f"},"id":"26r1m023JNmE","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  ieee-fraud-detection.zip\n","  inflating: sample_submission.csv   \n","  inflating: test_identity.csv       \n","  inflating: test_transaction.csv    \n","  inflating: train_identity.csv      \n","  inflating: train_transaction.csv   \n"]}]},{"cell_type":"code","source":["!python -m pip install --upgrade pip\n","!python -m pip install autogluon"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4jwU_6TJW9u","executionInfo":{"status":"ok","timestamp":1726179692337,"user_tz":420,"elapsed":369893,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"301331ec-304a-4de5-ed9b-10b68c1ff766"},"id":"e4jwU_6TJW9u","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n","Collecting pip\n","  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n","Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n","Installing collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 24.1.2\n","    Uninstalling pip-24.1.2:\n","      Successfully uninstalled pip-24.1.2\n","Successfully installed pip-24.2\n","Collecting autogluon\n","  Downloading autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\n","Collecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n","  Downloading autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n","Collecting autogluon.features==1.1.1 (from autogluon)\n","  Downloading autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n","Collecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n","  Downloading autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n","Collecting autogluon.multimodal==1.1.1 (from autogluon)\n","  Downloading autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\n","Collecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: numpy<1.29,>=1.21 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.4)\n","Collecting scipy<1.13,>=1.5.4 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n","Requirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.3.2)\n","Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3)\n","Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.1.4)\n","Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.66.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.32.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.1)\n","Collecting boto3<2,>=1.10 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading boto3-1.35.18-py3-none-any.whl.metadata (6.6 kB)\n","Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n","Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.1.1->autogluon) (0.2.7)\n","Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n","Collecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n","Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n","Collecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n","Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n","Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n","Collecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Collecting scikit-image<0.21.0,>=0.19.1 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Requirement already satisfied: text-unidecode<1.4,>=1.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\n","Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n","Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\n","Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n","Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n","Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: nltk<4.0.0,>=3.4.5 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (3.8.1)\n","Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n","Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\n","Requirement already satisfied: jinja2<3.2,>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.4)\n","Requirement already satisfied: tensorboard<3,>=2.9 in /usr/local/lib/python3.10/dist-packages (from autogluon.multimodal==1.1.1->autogluon) (2.17.0)\n","Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n","Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.1.1->autogluon)\n","  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n","Collecting xgboost<2.1,>=1.6 (from autogluon.tabular[all]==1.1.1->autogluon)\n","  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n","Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.7.17)\n","Collecting lightgbm<4.4,>=3.3 (from autogluon.tabular[all]==1.1.1->autogluon)\n","  Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl.metadata (19 kB)\n","Collecting catboost<1.3,>=1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n","  Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: joblib<2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.4.2)\n","Collecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n","Collecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\n","Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\n","Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n","Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n","Collecting orjson~=3.9 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","Collecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: psutil<6,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (71.0.4)\n","Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.9.1)\n","Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.1)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.12.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (24.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0.2)\n","Collecting botocore<1.36.0,>=1.35.18 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading botocore-1.35.18-py3-none-any.whl.metadata (5.7 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.3)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.15.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\n","Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading datasets-3.0.0-py3-none-any.whl.metadata (19 kB)\n","Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2024.6.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.24.6)\n","Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (24.2)\n","Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.0.7)\n","Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.7.5)\n","Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.3)\n","Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.7.6)\n","Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (1.0.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\n","Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.10.9.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.5)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (2023.12.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon) (0.20.0)\n","Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading lightning_utilities-0.11.7-py3-none-any.whl.metadata (5.2 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.60.0)\n","Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n","Requirement already satisfied: gdown>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (5.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2024.5.15)\n","Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting colorama (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n","Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.8.1)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.9.0)\n","Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.13.2)\n","Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n","Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n","Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n","Requirement already satisfied: protobuf>=3.20.1 in /usr/local/lib/python3.10/dist-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (3.20.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.16.0)\n","Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.8)\n","Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.1)\n","Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.4.1)\n","Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: pyarrow>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (14.0.2)\n","Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.10.5)\n","Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n","Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n","Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl.metadata (16 kB)\n","Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.20.0)\n","Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (7.0.4)\n","Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading virtualenv-20.26.4-py3-none-any.whl.metadata (4.5 kB)\n","Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.64.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.8.30)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.34.2)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2024.8.30)\n","Collecting PyWavelets>=1.1.1 (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n","Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.4)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.5.0)\n","Requirement already satisfied: statsmodels>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.2)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (1.4.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.0.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon) (0.4.5)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.3.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.10/dist-packages (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon) (0.1.99)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1.4)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.4.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.3)\n","Collecting pyarrow>=6.0.1 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.43.0)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (24.3.25)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.23.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.5)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.1.3)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (2.0.10)\n","Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.4.1)\n","Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.12.5)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (3.4.0)\n","Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.6)\n","Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading distlib-0.3.8-py2.py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.3.2)\n","Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n","Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n","Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.19.2)\n","Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n","Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading openxlab-0.1.1-py3-none-any.whl.metadata (3.8 kB)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (9.0.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.16.1)\n","Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.16.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.65.0)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.24.0)\n","Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (2.27.0)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.1.5)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.5.4)\n","Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (0.19.0)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (2.6)\n","Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n","Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading oss2-2.17.0.tar.gz (259 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pytz>=2020.1 (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n","  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n","INFO: pip is looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n","Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n","  Downloading openxlab-0.1.0-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.38-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.37-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.36-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.35-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.34-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.33-py3-none-any.whl.metadata (3.8 kB)\n","INFO: pip is still looking at multiple versions of openxlab to determine which version is compatible with other requirements. This could take a while.\n","  Downloading openxlab-0.0.32-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.31-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.30-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.29-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.28-py3-none-any.whl.metadata (3.7 kB)\n","INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading openxlab-0.0.27-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.26-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.25-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.24-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.23-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.22-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.21-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.20-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.19-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.18-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.17-py3-none-any.whl.metadata (3.7 kB)\n","  Downloading openxlab-0.0.16-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.15-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.14-py3-none-any.whl.metadata (3.8 kB)\n","  Downloading openxlab-0.0.13-py3-none-any.whl.metadata (4.5 kB)\n","  Downloading openxlab-0.0.12-py3-none-any.whl.metadata (4.5 kB)\n","  Downloading openxlab-0.0.11-py3-none-any.whl.metadata (4.3 kB)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (1.7.1)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.4.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.9)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (1.2.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.6.0)\n","Downloading autogluon-1.1.1-py3-none-any.whl (9.7 kB)\n","Downloading autogluon.core-1.1.1-py3-none-any.whl (234 kB)\n","Downloading autogluon.features-1.1.1-py3-none-any.whl (63 kB)\n","Downloading autogluon.multimodal-1.1.1-py3-none-any.whl (427 kB)\n","Downloading autogluon.tabular-1.1.1-py3-none-any.whl (312 kB)\n","Downloading autogluon.timeseries-1.1.1-py3-none-any.whl (148 kB)\n","Downloading autogluon.common-1.1.1-py3-none-any.whl (64 kB)\n","Downloading gluonts-0.15.1-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading accelerate-0.21.0-py3-none-any.whl (244 kB)\n","Downloading boto3-1.35.18-py3-none-any.whl (139 kB)\n","Downloading catboost-1.2.7-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n","Downloading lightgbm-4.3.0-py3-none-manylinux_2_28_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading lightning-2.3.3-py3-none-any.whl (808 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m808.5/808.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mlforecast-0.10.0-py3-none-any.whl (47 kB)\n","Downloading nlpaug-1.1.11-py3-none-any.whl (410 kB)\n","Downloading nptyping-2.4.1-py3-none-any.whl (36 kB)\n","Downloading omegaconf-2.2.3-py3-none-any.whl (79 kB)\n","Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n","Downloading optimum-1.18.1-py3-none-any.whl (410 kB)\n","Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n","Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m76.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n","Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytorch_metric_learning-2.3.0-py3-none-any.whl (115 kB)\n","Downloading ray-2.10.0-cp310-cp310-manylinux2014_x86_64.whl (65.1 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m65.1/65.1 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_image-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.2 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading statsforecast-1.4.0-py3-none-any.whl (91 kB)\n","Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchmetrics-1.2.1-py3-none-any.whl (806 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m806.1/806.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading utilsforecast-0.0.10-py3-none-any.whl (30 kB)\n","Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading botocore-1.35.18-py3-none-any.whl (12.5 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-3.0.0-py3-none-any.whl (474 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Downloading lightning_utilities-0.11.7-py3-none-any.whl (26 kB)\n","Downloading onnxruntime-1.19.2-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.2 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m71.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pywavelets-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading s3transfer-0.10.2-py3-none-any.whl (82 kB)\n","Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n","Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading virtualenv-20.26.4-py3-none-any.whl (6.0 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m94.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","Downloading colorful-0.5.6-py2.py3-none-any.whl (201 kB)\n","Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","Downloading onnx-1.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading opencensus-0.11.4-py2.py3-none-any.whl (128 kB)\n","Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n","Downloading window_ops-0.0.15-py3-none-any.whl (15 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n","Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n","Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openxlab-0.0.11-py3-none-any.whl (55 kB)\n","Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n","Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: nvidia-ml-py3, antlr4-python3-runtime, seqeval\n","  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19171 sha256=66d3c7c4b9eba3964f37157ad586eed8dcb6853e46c8cd5ea18052691d74dd3f\n","  Stored in directory: /root/.cache/pip/wheels/5c/d8/c0/46899f8be7a75a2ffd197a23c8797700ea858b9b34819fbf9e\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=17a4690a7102837b398d2634c9c160fb99ee64f84a3faf6c6fddc0fcc6a91220\n","  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=21652b23c5f904e2d9b7e8fbb104f86a6fdbc891c49c40af5afde5fe21ccba04\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built nvidia-ml-py3 antlr4-python3-runtime seqeval\n","Installing collected packages: py-spy, opencensus-context, nvidia-ml-py3, distlib, colorful, antlr4-python3-runtime, xxhash, virtualenv, triton, tensorboardX, scipy, PyWavelets, pycryptodome, pyarrow, Pillow, orjson, ordered-set, openxlab, onnx, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nptyping, lightning-utilities, jmespath, humanfriendly, dill, colorama, xgboost, window-ops, pytesseract, pdf2image, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, model-index, lightgbm, coloredlogs, botocore, utilsforecast, tokenizers, seqeval, scikit-image, s3transfer, opendatalab, onnxruntime, nvidia-cusolver-cu12, jsonschema, gluonts, catboost, transformers, torch, statsforecast, ray, openmim, opencensus, nlpaug, mlforecast, boto3, aiohttp-cors, torchvision, torchmetrics, pytorch-metric-learning, datasets, autogluon.common, accelerate, timm, pytorch-lightning, optimum, evaluate, autogluon.features, autogluon.core, lightning, autogluon.tabular, autogluon.multimodal, autogluon.timeseries, autogluon\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.13.1\n","    Uninstalling scipy-1.13.1:\n","      Successfully uninstalled scipy-1.13.1\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","  Attempting uninstall: Pillow\n","    Found existing installation: Pillow 9.4.0\n","    Uninstalling Pillow-9.4.0:\n","      Successfully uninstalled Pillow-9.4.0\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.22.3\n","    Uninstalling nvidia-nccl-cu12-2.22.3:\n","      Successfully uninstalled nvidia-nccl-cu12-2.22.3\n","  Attempting uninstall: xgboost\n","    Found existing installation: xgboost 2.1.1\n","    Uninstalling xgboost-2.1.1:\n","      Successfully uninstalled xgboost-2.1.1\n","  Attempting uninstall: lightgbm\n","    Found existing installation: lightgbm 4.4.0\n","    Uninstalling lightgbm-4.4.0:\n","      Successfully uninstalled lightgbm-4.4.0\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: scikit-image\n","    Found existing installation: scikit-image 0.23.2\n","    Uninstalling scikit-image-0.23.2:\n","      Successfully uninstalled scikit-image-0.23.2\n","  Attempting uninstall: jsonschema\n","    Found existing installation: jsonschema 4.23.0\n","    Uninstalling jsonschema-4.23.0:\n","      Successfully uninstalled jsonschema-4.23.0\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.2\n","    Uninstalling transformers-4.44.2:\n","      Successfully uninstalled transformers-4.44.2\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.4.0+cu121\n","    Uninstalling torch-2.4.0+cu121:\n","      Successfully uninstalled torch-2.4.0+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.19.0+cu121\n","    Uninstalling torchvision-0.19.0+cu121:\n","      Successfully uninstalled torchvision-0.19.0+cu121\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.34.2\n","    Uninstalling accelerate-0.34.2:\n","      Successfully uninstalled accelerate-0.34.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","albumentations 1.4.14 requires scikit-image>=0.21.0, but you have scikit-image 0.20.0 which is incompatible.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\n","osqp 0.6.7.post0 requires scipy!=1.12.0,>=0.13.2, but you have scipy 1.12.0 which is incompatible.\n","torchaudio 2.4.0+cu121 requires torch==2.4.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Pillow-10.4.0 PyWavelets-1.7.0 accelerate-0.21.0 aiohttp-cors-0.7.0 antlr4-python3-runtime-4.9.3 autogluon-1.1.1 autogluon.common-1.1.1 autogluon.core-1.1.1 autogluon.features-1.1.1 autogluon.multimodal-1.1.1 autogluon.tabular-1.1.1 autogluon.timeseries-1.1.1 boto3-1.35.18 botocore-1.35.18 catboost-1.2.7 colorama-0.4.6 coloredlogs-15.0.1 colorful-0.5.6 datasets-3.0.0 dill-0.3.8 distlib-0.3.8 evaluate-0.4.3 gluonts-0.15.1 humanfriendly-10.0 jmespath-1.0.1 jsonschema-4.21.1 lightgbm-4.3.0 lightning-2.3.3 lightning-utilities-0.11.7 mlforecast-0.10.0 model-index-0.1.11 multiprocess-0.70.16 nlpaug-1.1.11 nptyping-2.4.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-ml-py3-7.352.0 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 omegaconf-2.2.3 onnx-1.16.2 onnxruntime-1.19.2 opencensus-0.11.4 opencensus-context-0.1.3 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.11 optimum-1.18.1 ordered-set-4.1.0 orjson-3.10.7 pdf2image-1.17.0 py-spy-0.3.14 pyarrow-17.0.0 pycryptodome-3.20.0 pytesseract-0.3.10 pytorch-lightning-2.3.3 pytorch-metric-learning-2.3.0 ray-2.10.0 s3transfer-0.10.2 scikit-image-0.20.0 scipy-1.12.0 seqeval-1.2.2 statsforecast-1.4.0 tensorboardX-2.6.2.2 timm-0.9.16 tokenizers-0.15.2 torch-2.3.1 torchmetrics-1.2.1 torchvision-0.18.1 transformers-4.39.3 triton-2.3.1 utilsforecast-0.0.10 virtualenv-20.26.4 window-ops-0.0.15 xgboost-2.0.3 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["!pip install --upgrade pyarrow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAj13zo7OfsO","executionInfo":{"status":"ok","timestamp":1726179711709,"user_tz":420,"elapsed":13705,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"0be4049a-fede-4244-9a07-17e5adef7d57"},"id":"AAj13zo7OfsO","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n"]}]},{"cell_type":"code","source":["!ls /content/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kk9Y4T45M2YY","executionInfo":{"status":"ok","timestamp":1726179711710,"user_tz":420,"elapsed":22,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"0bf630f1-926e-4a12-c4f2-8dc941f6a59a"},"id":"kk9Y4T45M2YY","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ieee-fraud-detection.zip  sample_data\t\t test_identity.csv     train_identity.csv\n","kaggle.json\t\t  sample_submission.csv  test_transaction.csv  train_transaction.csv\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from autogluon.tabular import TabularPredictor\n","\n","directory = '/content/' # directory where you have downloaded the data CSV files from the competition\n","label = 'isFraud'  # name of target variable to predict in this competition\n","eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n","save_path = directory + 'AutoGluonModels/'  # where to store trained models\n","\n","train_identity = pd.read_csv(directory+'train_identity.csv')\n","train_transaction = pd.read_csv(directory+'train_transaction.csv')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":383},"id":"4h8Aa1ZeG61N","executionInfo":{"status":"error","timestamp":1726180536673,"user_tz":420,"elapsed":2273,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"9548497a-55b4-4fc3-f41d-e4ba0379cdb1"},"id":"4h8Aa1ZeG61N","execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'autogluon'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-bd8ffc04fab3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mautogluon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtabular\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTabularPredictor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/'\u001b[0m \u001b[0;31m# directory where you have downloaded the data CSV files from the competition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autogluon'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"markdown","id":"a6057bf4","metadata":{"id":"a6057bf4"},"source":["```\n","import pandas as pd\n","import numpy as np\n","from autogluon.tabular import TabularPredictor\n","\n","directory = '~/IEEEfraud/'  # directory where you have downloaded the data CSV files from the competition\n","label = 'isFraud'  # name of target variable to predict in this competition\n","eval_metric = 'roc_auc'  # Optional: specify that competition evaluation metric is AUC\n","save_path = directory + 'AutoGluonModels/'  # where to store trained models\n","\n","train_identity = pd.read_csv(directory+'train_identity.csv')\n","train_transaction = pd.read_csv(directory+'train_transaction.csv')\n","```\n"]},{"cell_type":"markdown","id":"1b046735","metadata":{"id":"1b046735"},"source":["Since the training data for this competition is comprised of multiple CSV files, we just first join them into a single large table (with rows = examples, columns = features) before applying AutoGluon:"]},{"cell_type":"markdown","id":"9ddbf2bd","metadata":{"id":"9ddbf2bd"},"source":["```\n","train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')\n","```\n"]},{"cell_type":"code","source":["train_data = pd.merge(train_transaction, train_identity, on='TransactionID', how='left')"],"metadata":{"id":"UMfUmtT_KMvv"},"id":"UMfUmtT_KMvv","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"7de8c287","metadata":{"id":"7de8c287"},"source":["Note that a left-join on the `TransactionID` key happened to be most appropriate for this Kaggle competition, but for others involving multiple training data files, you will likely need to use a different join strategy (always consider this very carefully). Now that all our training data resides within a single table, we can apply AutoGluon. Below, we specify the `presets` argument to maximize AutoGluon's predictive accuracy which usually requires that you run `fit()` with longer time limits (3600s below should likely be increased in your run):"]},{"cell_type":"markdown","id":"aaad348b","metadata":{"id":"aaad348b"},"source":["```\n","predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n","    train_data, presets='best_quality', time_limit=3600\n",")\n","\n","results = predictor.fit_summary()\n","```\n"]},{"cell_type":"code","source":["predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n","    train_data, presets='good_quality', time_limit=60\n",")\n","\n","results = predictor.fit_summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"NbDbFq39KN_W","executionInfo":{"status":"error","timestamp":1726180007357,"user_tz":420,"elapsed":30321,"user":{"displayName":"Praful John","userId":"06870105923946897201"}},"outputId":"7425c3d8-d1e3-458c-fda7-0dd3abbad32b"},"id":"NbDbFq39KN_W","execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/content/AutoGluonModels/\"\n","Verbosity: 3 (Detailed Logging)\n","=================== System Info ===================\n","AutoGluon Version:  1.1.1\n","Python Version:     3.10.12\n","Operating System:   Linux\n","Platform Machine:   x86_64\n","Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n","CPU Count:          2\n","GPU Count:          0\n","Memory Avail:       5.92 GB / 12.67 GB (46.7%)\n","Disk Space Avail:   64.01 GB / 107.72 GB (59.4%)\n","===================================================\n","Presets specified: ['good_quality']\n","============ fit kwarg info ============\n","User Specified kwargs:\n","{'auto_stack': True,\n"," 'num_bag_sets': 1,\n"," 'refit_full': True,\n"," 'save_bag_folds': False,\n"," 'set_best_to_refit_full': True}\n","Full kwargs:\n","{'_feature_generator_kwargs': None,\n"," '_save_bag_folds': None,\n"," 'ag_args': None,\n"," 'ag_args_ensemble': None,\n"," 'ag_args_fit': None,\n"," 'auto_stack': True,\n"," 'calibrate': 'auto',\n"," 'ds_args': {'clean_up_fits': True,\n","             'detection_time_frac': 0.25,\n","             'enable_ray_logging': True,\n","             'holdout_data': None,\n","             'holdout_frac': 0.1111111111111111,\n","             'memory_safe_fits': True,\n","             'n_folds': 2,\n","             'n_repeats': 1,\n","             'validation_procedure': 'holdout'},\n"," 'excluded_model_types': None,\n"," 'feature_generator': 'auto',\n"," 'feature_prune_kwargs': None,\n"," 'holdout_frac': None,\n"," 'hyperparameter_tune_kwargs': None,\n"," 'included_model_types': None,\n"," 'keep_only_best': False,\n"," 'name_suffix': None,\n"," 'num_bag_folds': None,\n"," 'num_bag_sets': 1,\n"," 'num_stack_levels': None,\n"," 'pseudo_data': None,\n"," 'refit_full': True,\n"," 'save_bag_folds': False,\n"," 'save_space': False,\n"," 'set_best_to_refit_full': True,\n"," 'unlabeled_data': None,\n"," 'use_bag_holdout': False,\n"," 'verbosity': 3}\n","========================================\n","Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n","Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n","Note: `save_bag_folds=False`! This will greatly reduce peak disk usage during fit (by ~8x), but runs the risk of an out-of-memory error during model refit if memory is small relative to the data size.\n","\tYou can avoid this risk by setting `save_bag_folds=True`.\n","DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n","\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n","\tRunning DyStack for up to 15s of the 60s of remaining time (25%).\n","\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n","2024-09-12 22:26:28,134\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n","\t\tContext path: \"/content/AutoGluonModels/ds_sub_fit/sub_fit_ho\"\n"]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.28.0.12, ID: da181b52d11334c1b33b87cf53fb205d42f598b3a39744e9a286211d) where the task (task ID: e8cb9aaa18bdeb31e3f1ad01ec942b3a89a1806701000000, name=_dystack, pid=5356, memory used=3.05GB) was running was 12.05GB / 12.67GB (0.950508), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 0fa5c82f65d002893af63a03950cc4481d7a31cda7034e3b286f2cc3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-0fa5c82f65d002893af63a03950cc4481d7a31cda7034e3b286f2cc3*out -ip 172.28.0.12. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n4616\t5.45\t/usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter/runtime/kernel-2edf9cb6-ec82...\n5356\t3.05\tray::_dystack\n4698\t0.39\tnode /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:0d81efaea4dacaa60...\n95\t0.11\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n5250\t0.07\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n5338\t0.06\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n7\t0.06\t/tools/node/bin/node /datalab/web/app.js\n5245\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n5296\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --session-di...\n5340\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/runtime_env/agent/main.py -...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-7ea9ac1cbfc3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m predictor = TabularPredictor(label=label, eval_metric=eval_metric, path=save_path, verbosity=3).fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpresets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'good_quality'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/core/utils/decorators.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mother_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, infer_limit, infer_limit_batch_size, fit_weighted_ensemble, fit_full_last_level_weighted_ensemble, full_weighted_ensemble_additionally, dynamic_stacking, calibrate_decision_threshold, num_cpus, num_gpus, **kwargs)\u001b[0m\n\u001b[1;32m   1149\u001b[0m                 \u001b[0;34m\"AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m             )\n\u001b[0;32m-> 1151\u001b[0;31m             \u001b[0mnum_stack_levels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamic_stacking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mds_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_fit_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_post_fit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m             logger.info(\n\u001b[1;32m   1153\u001b[0m                 \u001b[0;34mf\"Starting main fit with num_stack_levels={num_stack_levels}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_dynamic_stacking\u001b[0;34m(self, ag_fit_kwargs, ag_post_fit_kwargs, validation_procedure, detection_time_frac, holdout_frac, n_folds, n_repeats, memory_safe_fits, clean_up_fits, enable_ray_logging, holdout_data)\u001b[0m\n\u001b[1;32m   1240\u001b[0m                 \u001b[0mds_fit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ds_fit_context\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_fit_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sub_fit_custom_ho\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1242\u001b[0;31m             stacked_overfitting = self._sub_fit_memory_save_wrapper(\n\u001b[0m\u001b[1;32m   1243\u001b[0m                 \u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 \u001b[0mtime_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/autogluon/tabular/predictor/predictor.py\u001b[0m in \u001b[0;36m_sub_fit_memory_save_wrapper\u001b[0;34m(self, train_data, time_limit, time_start, ds_fit_kwargs, ag_fit_kwargs, ag_post_fit_kwargs, holdout_data)\u001b[0m\n\u001b[1;32m   1423\u001b[0m                 )\n\u001b[1;32m   1424\u001b[0m                 \u001b[0mfinished\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munfinished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ds_ray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_returns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1425\u001b[0;31m                 \u001b[0mstacked_overfitting\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mho_leaderboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ds_ray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinished\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1427\u001b[0m                 \u001b[0;31m# TODO: This is present to ensure worker logs are properly logged and don't get skipped / printed out of order.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\u001b[0m in \u001b[0;36mauto_init_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mauto_init_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauto_init_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"init\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_client_mode_enabled_by_default\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(object_refs, timeout)\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m         \u001b[0;31m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m         \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugger_breakpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_refs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRayError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\u001b[0m in \u001b[0;36mget_objects\u001b[0;34m(self, object_refs, timeout)\u001b[0m\n\u001b[1;32m    864\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_instanceof_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebugger_breakpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: Task was killed due to the node running low on memory.\nMemory on the node (IP: 172.28.0.12, ID: da181b52d11334c1b33b87cf53fb205d42f598b3a39744e9a286211d) where the task (task ID: e8cb9aaa18bdeb31e3f1ad01ec942b3a89a1806701000000, name=_dystack, pid=5356, memory used=3.05GB) was running was 12.05GB / 12.67GB (0.950508), which exceeds the memory usage threshold of 0.95. Ray killed this worker (ID: 0fa5c82f65d002893af63a03950cc4481d7a31cda7034e3b286f2cc3) because it was the most recently scheduled task; to see more information about memory usage on this node, use `ray logs raylet.out -ip 172.28.0.12`. To see the logs of the worker, use `ray logs worker-0fa5c82f65d002893af63a03950cc4481d7a31cda7034e3b286f2cc3*out -ip 172.28.0.12. Top 10 memory users:\nPID\tMEM(GB)\tCOMMAND\n4616\t5.45\t/usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter/runtime/kernel-2edf9cb6-ec82...\n5356\t3.05\tray::_dystack\n4698\t0.39\tnode /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:0d81efaea4dacaa60...\n95\t0.11\t/usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --Notebo...\n5250\t0.07\t/usr/bin/python3 /usr/local/lib/python3.10/dist-packages/ray/dashboard/dashboard.py --host=127.0.0.1...\n5338\t0.06\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/dashboard/agent.py --node-ip-address...\n7\t0.06\t/tools/node/bin/node /datalab/web/app.js\n5245\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/autoscaler/_private/monitor.py --log...\n5296\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/log_monitor.py --session-di...\n5340\t0.04\t/usr/bin/python3 -u /usr/local/lib/python3.10/dist-packages/ray/_private/runtime_env/agent/main.py -...\nRefer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero."]}]},{"cell_type":"markdown","id":"010f5fef","metadata":{"id":"010f5fef"},"source":["Now, we use the trained AutoGluon Predictor to make predictions on the competition's test data. It is imperative that multiple test data files are joined together in the exact same manner as the training data. Because this competition is evaluated based on the AUC (Area under the ROC curve) metric, we ask AutoGluon for predicted class-probabilities rather than class predictions. In general, when to use `predict` vs `predict_proba` will depend on the particular competition."]},{"cell_type":"markdown","id":"75bc10a9","metadata":{"id":"75bc10a9"},"source":["```\n","test_identity = pd.read_csv(directory+'test_identity.csv')\n","test_transaction = pd.read_csv(directory+'test_transaction.csv')\n","test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n","\n","y_predproba = predictor.predict_proba(test_data)\n","y_predproba.head(5)  # some example predicted fraud-probabilities\n","```\n"]},{"cell_type":"code","source":["test_identity = pd.read_csv(directory+'test_identity.csv')\n","test_transaction = pd.read_csv(directory+'test_transaction.csv')\n","test_data = pd.merge(test_transaction, test_identity, on='TransactionID', how='left')  # same join applied to training files\n","\n","y_predproba = predictor.predict_proba(test_data)\n","y_predproba.head(5)  # some example predicted fraud-probabilities"],"metadata":{"id":"4bvBk6ZgKPc5"},"id":"4bvBk6ZgKPc5","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"2cd379db","metadata":{"id":"2cd379db"},"source":["When submitting predicted probabilities for classification competitions, it is imperative these correspond to the same class expected by Kaggle. For binary classification tasks, you can see which class AutoGluon's predicted probabilities correspond to via:"]},{"cell_type":"markdown","id":"79b65205","metadata":{"id":"79b65205"},"source":["```\n","predictor.positive_class\n","```\n"]},{"cell_type":"code","source":["predictor.positive_class"],"metadata":{"id":"-UkMqwRRKQ95"},"id":"-UkMqwRRKQ95","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"bb03739b","metadata":{"id":"bb03739b"},"source":["For multiclass classification tasks, you can see which classes AutoGluon's predicted probabilities correspond to via:"]},{"cell_type":"markdown","id":"9020a4f9","metadata":{"id":"9020a4f9"},"source":["```\n","predictor.class_labels  # classes in this list correspond to columns of predict_proba() output\n","```\n"]},{"cell_type":"code","source":["predictor.class_labels  # classes in this list correspond to columns of predict_proba() output"],"metadata":{"id":"FjrDfBLZKSGj"},"id":"FjrDfBLZKSGj","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"8cb84c3e","metadata":{"id":"8cb84c3e"},"source":["Now, let's get prediction probabilities for the entire test data, while only getting the positive class predictions by specifying:"]},{"cell_type":"markdown","id":"3e82e4c9","metadata":{"id":"3e82e4c9"},"source":["```\n","y_predproba = predictor.predict_proba(test_data, as_multiclass=False)\n","```\n"]},{"cell_type":"code","source":["y_predproba = predictor.predict_proba(test_data, as_multiclass=False)"],"metadata":{"id":"sGR6l_HnKTZr"},"id":"sGR6l_HnKTZr","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"9f26a317","metadata":{"id":"9f26a317"},"source":["Now that we have made a prediction for each row in the test dataset, we can submit these predictions to Kaggle. Most Kaggle competitions provide a sample submission file, in which you can simply overwrite the sample predictions with your own as we do below:"]},{"cell_type":"markdown","id":"ef9ae74e","metadata":{"id":"ef9ae74e"},"source":["```\n","submission = pd.read_csv(directory+'sample_submission.csv')\n","submission['isFraud'] = y_predproba\n","submission.head()\n","submission.to_csv(directory+'my_submission.csv', index=False)\n","```\n"]},{"cell_type":"code","source":["submission = pd.read_csv(directory+'sample_submission.csv')\n","submission['isFraud'] = y_predproba\n","submission.head()\n","submission.to_csv(directory+'my_submission.csv', index=False)"],"metadata":{"id":"24ZnJ316KUot"},"id":"24ZnJ316KUot","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"2fd99892","metadata":{"id":"2fd99892"},"source":["We have now completed steps (4)-(6) from the top of this tutorial. To submit your predictions to Kaggle, you can run the following command in your terminal (from the appropriate directory):\n","\n","`kaggle competitions submit -c ieee-fraud-detection -f sample_submission.csv -m \"my first submission\"`\n","\n","You can now play with different `fit()` arguments and feature-engineering techniques to try and maximize the rank of your submissions in the Kaggle Leaderboard!\n","\n","\n","**Tips to maximize predictive performance:**\n","\n","   - Be sure to specify the appropriate evaluation metric if one is specified on the competition website! If you are unsure which metric is best, then simply do not specify this argument when invoking `fit()`; AutoGluon should still produce high-quality models by automatically inferring which metric to use.\n","\n","   - If the training examples are time-based and the competition test examples come from future data, we recommend you reserve the most recently-collected training examples as a separate validation dataset passed to `fit()`. Otherwise, you do not need to specify a validation set yourself and AutoGluon will automatically partition the competition training data into its own training/validation sets.\n","\n","   - Beyond simply specifying `presets = 'best_quality'`, you may play with more advanced `fit()` arguments such as: `num_bag_folds`, `num_stack_levels`, `num_bag_sets`, `hyperparameter_tune_kwargs`, `hyperparameters`, `refit_full`. However we recommend spending most of your time on feature-engineering and just specify `presets = 'best_quality'` inside the call to `fit()`.\n","\n","\n","**Troubleshooting:**\n","\n","- Check that you have the right user-permissions on your computer to access the data files downloaded from Kaggle.\n","\n","- For issues downloading Kaggle data or submitting predictions, check your Kaggle account setup and the [Kaggle FAQ](https://www.kaggle.com/general/14438)."]}],"metadata":{"language_info":{"name":"python"},"colab":{"provenance":[{"file_id":"https://github.com/autogluon/autogluon/blob/stable/docs/tutorials/tabular/advanced/tabular-kaggle.ipynb","timestamp":1726005582280}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}